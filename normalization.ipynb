{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "B, W, E = inputs.size()  #batch size, no. of words, embedding for a batch\n",
    "inputs = inputs.reshape(W, B, E)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta =  nn.Parameter(torch.zeros(parameter_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [-(i + 1) for i in range(len(parameter_shape))] #Dimensions for which to compute normalization: batch and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim=dims, keepdim=True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()\n",
    "y = (inputs - mean) / std\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = gamma * y + beta\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Normalization():\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
    "        output = self.gamma * y  + self.beta\n",
    "        print(f\"out \\n ({output.size()}) = \\n {output}\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input \n",
      " (torch.Size([4, 3, 8])) = \n",
      " tensor([[[ 0.8732,  0.8488,  0.1720, -0.1793,  0.7333, -0.9600, -1.0085,\n",
      "           1.3496],\n",
      "         [-0.1007, -0.6165,  0.8324, -2.2993,  0.6018,  0.4077, -0.2467,\n",
      "          -0.5008],\n",
      "         [ 0.0466,  0.2815, -0.2698, -0.6876, -0.4209, -0.1700, -0.8521,\n",
      "           0.9155]],\n",
      "\n",
      "        [[ 0.0042,  1.0113,  0.1568,  0.4589, -0.7188, -1.2711,  0.5005,\n",
      "           1.5250],\n",
      "         [-0.0371,  0.3279,  2.3972,  0.5790,  0.5150,  0.6903,  0.8016,\n",
      "          -1.5472],\n",
      "         [-1.3012,  1.4258, -0.7413, -1.5327, -0.2613, -0.6357, -1.8437,\n",
      "           1.6475]],\n",
      "\n",
      "        [[ 0.3957, -0.3621,  0.1139,  0.4707,  0.5018, -1.0613,  0.3563,\n",
      "          -0.1848],\n",
      "         [ 0.1086,  0.7377, -0.0471,  0.2584,  0.6483, -2.6424,  0.0730,\n",
      "           0.7366],\n",
      "         [ 0.5479,  0.9551, -1.5742, -0.1763,  1.3702, -0.4154,  0.0106,\n",
      "          -0.8223]],\n",
      "\n",
      "        [[ 0.8055,  1.7578,  0.7961, -0.8395,  0.5807,  1.2985, -1.5671,\n",
      "          -1.0510],\n",
      "         [ 0.0862, -0.8279, -0.2827,  0.9684,  0.2332, -1.4724, -0.2981,\n",
      "           0.3274],\n",
      "         [-1.9447,  0.5631, -1.1864, -2.0288,  0.6962,  0.1326,  1.2089,\n",
      "          -0.8001]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 3\n",
    "sentence_length = 4\n",
    "embedding_dim = 8 \n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
    "\n",
    "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normlzn = Normalization(inputs.size()[-1:]) ##normalization on layer dim: embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y \n",
      " (torch.Size([4, 3, 8])) = \n",
      " tensor([[[ 0.7828,  0.7531, -0.0688, -0.4954,  0.6129, -1.4435, -1.5024,\n",
      "           1.3614],\n",
      "         [ 0.1520, -0.4097,  1.1679, -2.2419,  0.9169,  0.7055, -0.0070,\n",
      "          -0.2837],\n",
      "         [ 0.3622,  0.8070, -0.2372, -1.0285, -0.5232, -0.0481, -1.3401,\n",
      "           2.0079]],\n",
      "\n",
      "        [[-0.2436,  0.9580, -0.0615,  0.2989, -1.1063, -1.7652,  0.3486,\n",
      "           1.5710],\n",
      "         [-0.4958, -0.1360,  1.9038,  0.1116,  0.0485,  0.2213,  0.3310,\n",
      "          -1.9844],\n",
      "         [-0.7347,  1.5016, -0.2755, -0.9245,  0.1181, -0.1889, -1.1795,\n",
      "           1.6834]],\n",
      "\n",
      "        [[ 0.7240, -0.7712,  0.1680,  0.8719,  0.9334, -2.1508,  0.6461,\n",
      "          -0.4214],\n",
      "         [ 0.1203,  0.7279, -0.0301,  0.2649,  0.6416, -2.5372,  0.0858,\n",
      "           0.7268],\n",
      "         [ 0.6249,  1.0785, -1.7391, -0.1819,  1.5409, -0.4482,  0.0264,\n",
      "          -0.9015]],\n",
      "\n",
      "        [[ 0.5146,  1.3553,  0.5062, -0.9377,  0.3161,  0.9499, -1.5800,\n",
      "          -1.1244],\n",
      "         [ 0.3489, -0.9556, -0.1776,  1.6077,  0.5586, -1.8753, -0.1996,\n",
      "           0.6930],\n",
      "         [-1.3114,  0.8454, -0.6592, -1.3837,  0.9599,  0.4752,  1.4008,\n",
      "          -0.3270]]])\n",
      "out \n",
      " (torch.Size([4, 3, 8])) = \n",
      " tensor([[[ 0.7828,  0.7531, -0.0688, -0.4954,  0.6129, -1.4435, -1.5024,\n",
      "           1.3614],\n",
      "         [ 0.1520, -0.4097,  1.1679, -2.2419,  0.9169,  0.7055, -0.0070,\n",
      "          -0.2837],\n",
      "         [ 0.3622,  0.8070, -0.2372, -1.0285, -0.5232, -0.0481, -1.3401,\n",
      "           2.0079]],\n",
      "\n",
      "        [[-0.2436,  0.9580, -0.0615,  0.2989, -1.1063, -1.7652,  0.3486,\n",
      "           1.5710],\n",
      "         [-0.4958, -0.1360,  1.9038,  0.1116,  0.0485,  0.2213,  0.3310,\n",
      "          -1.9844],\n",
      "         [-0.7347,  1.5016, -0.2755, -0.9245,  0.1181, -0.1889, -1.1795,\n",
      "           1.6834]],\n",
      "\n",
      "        [[ 0.7240, -0.7712,  0.1680,  0.8719,  0.9334, -2.1508,  0.6461,\n",
      "          -0.4214],\n",
      "         [ 0.1203,  0.7279, -0.0301,  0.2649,  0.6416, -2.5372,  0.0858,\n",
      "           0.7268],\n",
      "         [ 0.6249,  1.0785, -1.7391, -0.1819,  1.5409, -0.4482,  0.0264,\n",
      "          -0.9015]],\n",
      "\n",
      "        [[ 0.5146,  1.3553,  0.5062, -0.9377,  0.3161,  0.9499, -1.5800,\n",
      "          -1.1244],\n",
      "         [ 0.3489, -0.9556, -0.1776,  1.6077,  0.5586, -1.8753, -0.1996,\n",
      "           0.6930],\n",
      "         [-1.3114,  0.8454, -0.6592, -1.3837,  0.9599,  0.4752,  1.4008,\n",
      "          -0.3270]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = normlzn.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
